{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09c7a06",
   "metadata": {},
   "source": [
    "# InceptionV3 Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c385d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1100cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your training, validation, and test sets\n",
    "train_dir = 'C:/Users/user/Downloads/archive (3)/train_set'\n",
    "validation_dir = 'C:/Users/user/Downloads/archive (3)/validation_set'\n",
    "test_dir = 'C:/Users/user/Downloads/archive (3)/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d670841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 images belonging to 2 classes.\n",
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d6f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1043a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "914a17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac2618f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 200s 11s/step - loss: 0.7092 - accuracy: 0.5571 - val_loss: 1.0002 - val_accuracy: 0.4062\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 134s 9s/step - loss: 0.5338 - accuracy: 0.7214 - val_loss: 0.7123 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 134s 9s/step - loss: 0.3934 - accuracy: 0.8452 - val_loss: 0.5632 - val_accuracy: 0.7031\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 129s 9s/step - loss: 0.3001 - accuracy: 0.8738 - val_loss: 0.5904 - val_accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 129s 9s/step - loss: 0.3093 - accuracy: 0.8548 - val_loss: 0.7318 - val_accuracy: 0.6406\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 130s 9s/step - loss: 0.3657 - accuracy: 0.8357 - val_loss: 0.8000 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 129s 9s/step - loss: 0.2385 - accuracy: 0.9000 - val_loss: 0.9294 - val_accuracy: 0.6094\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 132s 9s/step - loss: 0.2531 - accuracy: 0.8881 - val_loss: 1.0272 - val_accuracy: 0.6719\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 128s 9s/step - loss: 0.1430 - accuracy: 0.9476 - val_loss: 1.3051 - val_accuracy: 0.5781\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 129s 9s/step - loss: 0.2093 - accuracy: 0.9262 - val_loss: 0.9678 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e665cda8e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8ba3d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d774d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 8s 3s/step - loss: 0.6479 - accuracy: 0.6915\n",
      "Test Accuracy: 0.6914893388748169\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44430cc5",
   "metadata": {},
   "source": [
    "## Below is fine tuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cc0cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze some top layers for fine-tuning\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb32905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model again for fine-tuning\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3280bc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 64s 4s/step - loss: 0.2715 - accuracy: 0.8795 - val_loss: 0.7938 - val_accuracy: 0.6562\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 56s 4s/step - loss: 0.2127 - accuracy: 0.8929 - val_loss: 1.2775 - val_accuracy: 0.7031\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.2342 - accuracy: 0.9119 - val_loss: 1.3075 - val_accuracy: 0.6562\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.1881 - accuracy: 0.9190 - val_loss: 1.3156 - val_accuracy: 0.6719\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.1521 - accuracy: 0.9357 - val_loss: 1.2882 - val_accuracy: 0.6875\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 50s 3s/step - loss: 0.1743 - accuracy: 0.9381 - val_loss: 1.6144 - val_accuracy: 0.6562\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 49s 3s/step - loss: 0.1380 - accuracy: 0.9500 - val_loss: 1.4513 - val_accuracy: 0.6406\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 50s 3s/step - loss: 0.1054 - accuracy: 0.9619 - val_loss: 1.0672 - val_accuracy: 0.7188\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.1690 - accuracy: 0.9262 - val_loss: 1.4489 - val_accuracy: 0.6719\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.1597 - accuracy: 0.9333 - val_loss: 1.2302 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e66d460a30>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training the entire model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,  # You can adjust the number of epochs as needed\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b4e6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step - loss: 1.1670 - accuracy: 0.7340\n",
      "Validation Accuracy: 0.7340425252914429\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80d0d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 8s 2s/step - loss: 1.1590 - accuracy: 0.6809\n",
      "Test Accuracy: 0.6808510422706604\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264622e",
   "metadata": {},
   "source": [
    "### Testing with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6114ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify a single image\n",
    "def classify_image(img_path):\n",
    "    img = load_img(img_path, target_size=(299, 299))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Rescale pixel values to [0, 1]\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    if prediction[0] >= 0.5:\n",
    "        return \"Pneumonia\"\n",
    "    else:\n",
    "        return \"Non-Pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd7cd33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Classification Result: Pneumonia\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path_to_classify = r'C:\\Users\\user\\Downloads\\archive (3)\\Pneumonia photos\\00030621_002.png'\n",
    "classification_result = classify_image(image_path_to_classify)\n",
    "print(\"Classification Result:\", classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9049a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "Classification Result: Non-Pneumonia\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path_to_classify = r'C:\\Users\\user\\Downloads\\archive (3)\\Non-pneumonia photos\\00000078_000.png'\n",
    "classification_result = classify_image(image_path_to_classify)\n",
    "print(\"Classification Result:\", classification_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f128847",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53ab2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebbe1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "482563ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4647c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Adjust target size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "409d6b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),  # Adjust target size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a35a5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9649ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ee1a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 12s 844ms/step - loss: 0.6977 - accuracy: 0.5190 - val_loss: 0.6951 - val_accuracy: 0.4844\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 12s 841ms/step - loss: 0.6872 - accuracy: 0.5452 - val_loss: 0.6970 - val_accuracy: 0.5156\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 14s 993ms/step - loss: 0.6981 - accuracy: 0.5143 - val_loss: 0.6908 - val_accuracy: 0.5625\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 13s 960ms/step - loss: 0.6934 - accuracy: 0.5119 - val_loss: 0.6879 - val_accuracy: 0.5938\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 13s 953ms/step - loss: 0.6892 - accuracy: 0.5310 - val_loss: 0.6896 - val_accuracy: 0.5781\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 13s 968ms/step - loss: 0.6851 - accuracy: 0.5476 - val_loss: 0.6851 - val_accuracy: 0.5312\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 14s 992ms/step - loss: 0.6930 - accuracy: 0.5381 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6840 - accuracy: 0.5446 - val_loss: 0.6902 - val_accuracy: 0.5781\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.6830 - accuracy: 0.5714 - val_loss: 0.6691 - val_accuracy: 0.5781\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6848 - accuracy: 0.5619 - val_loss: 0.7184 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b6045d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),  # Adjust target size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2aebc098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 477ms/step - loss: 0.6910 - accuracy: 0.5426\n",
      "Test Accuracy: 0.542553186416626\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0ddc2",
   "metadata": {},
   "source": [
    "## Below is fine tuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4af81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94e828ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e851e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Define your custom model architecture\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers except the last few\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71a684cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.6511 - accuracy: 0.6405 - val_loss: 0.7559 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.5737 - accuracy: 0.7024 - val_loss: 0.6468 - val_accuracy: 0.5938\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.5479 - accuracy: 0.7310 - val_loss: 0.6351 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.5143 - accuracy: 0.7786 - val_loss: 0.7033 - val_accuracy: 0.6406\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.5117 - accuracy: 0.7286 - val_loss: 0.6377 - val_accuracy: 0.6875\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.5223 - accuracy: 0.7286 - val_loss: 0.6380 - val_accuracy: 0.6406\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.4912 - accuracy: 0.7762 - val_loss: 0.5646 - val_accuracy: 0.7344\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.4810 - accuracy: 0.7595 - val_loss: 0.6077 - val_accuracy: 0.7656\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.4648 - accuracy: 0.7738 - val_loss: 0.5989 - val_accuracy: 0.6875\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.4748 - accuracy: 0.7905 - val_loss: 0.6264 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e677dc0fd0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6a3ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8f5e8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 2s/step - loss: 0.6630 - accuracy: 0.6489\n",
      "Test Accuracy: 0.6489361524581909\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d77c209",
   "metadata": {},
   "source": [
    "### Testing with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a9f9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a single image\n",
    "def classify_single_image(img_path):\n",
    "    # Load the image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    # Convert image to array\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Normalize pixel values\n",
    "    img_array /= 255.\n",
    "\n",
    "    # Predict class\n",
    "    prediction = model.predict(img_array)\n",
    "    if prediction[0] >= 0.5:\n",
    "        return \"Pneumonia\"\n",
    "    else:\n",
    "        return \"Non-Pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3010d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Classification Result: Pneumonia\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path_to_classify = r'C:\\Users\\user\\Downloads\\archive (3)\\Pneumonia photos\\00030621_002.png'\n",
    "classification_result = classify_single_image(image_path_to_classify)\n",
    "print(\"Classification Result:\", classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55508570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "Classification Result: Non-Pneumonia\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path_to_classify = r'C:\\Users\\user\\Downloads\\archive (3)\\Non-pneumonia photos\\00000013_010.png'\n",
    "classification_result = classify_image(image_path_to_classify)\n",
    "print(\"Classification Result:\", classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276d124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
